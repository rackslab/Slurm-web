#!/usr/bin/env python3
#
# Copyright (c) 2024 Rackslab
#
# This file is part of Slurm-web.
#
# SPDX-License-Identifier: MIT

from pathlib import Path
import argparse
import shutil
import sys
import getpass
import logging

from rfl.log import setup_logger

from crawler.lib import (
    load_settings,
    DevelopmentHostClient,
    DevelopmentHostConnectionError,
    DevelopmentHostCluster,
)
from crawler.slurmrestd import SlurmrestdCrawler
from crawler.agent import crawl_agent
from crawler.gateway import slurmweb_token, GatewayCrawler
from crawler.prometheus import crawl_prometheus

from racksdb import RacksDB
from slurmweb.slurmrestd.auth import SlurmrestdAuthentifier

logger = logging.getLogger("crawl-tests-assets")

DEBUG_FLAGS = ["slurmweb", "rfl", "werkzeug", "urllib3", "crawler"]
DEV_HOST = "firehpc.dev.rackslab.io"
USER = getpass.getuser()
GATEWAY_PREFERRED_INFRASTRUCTURE = "tiny"
METRICS_PREFERRED_INFRASTRUCTURE = "emulator"
# Map between infrastructure names and cluster names that are visible in Slurm-web.
MAP_CLUSTER_NAMES = {"emulator": "atlas"}

ASSETS_ROOT = Path("tests/assets")


class SimpleProgressBar:
    """Simple progress bar for TTY output, spanning full terminal width."""

    def __init__(self, total: int):
        self.total = total
        self.current = 0
        self._update_display()

    def _update_display(self):
        """Update the progress bar display."""
        # Get current terminal width (may change if terminal is resized)
        terminal_width = shutil.get_terminal_size().columns

        if self.total == 0:
            percent = 100
        else:
            percent = int((self.current / self.total) * 100)

        # Calculate available width for the progress bar
        # Reserve space for: "Progress: [", "]", " XXX% (XXX/XXX)"
        prefix = "Progress: ["
        suffix = f"] {percent}% ({self.current}/{self.total})"
        reserved_width = len(prefix) + len(suffix)
        bar_length = max(1, terminal_width - reserved_width)

        filled = int((self.current / self.total) * bar_length) if self.total > 0 else 0
        bar = "=" * filled + "-" * (bar_length - filled)
        sys.stdout.write(f"\r{prefix}{bar}{suffix}")
        sys.stdout.flush()

    def update(self, n: int = 1):
        """Update progress by n items."""
        self.current += n
        if self.current > self.total:
            self.current = self.total
        self._update_display()

    def close(self):
        """Close the progress bar."""
        sys.stdout.write("\n")
        sys.stdout.flush()


def slurmweb_cluster_name(infrastructure: str):
    return MAP_CLUSTER_NAMES.get(infrastructure, infrastructure)


def _run_crawl(
    clusters_to_process: list[str],
    components_to_process: list[str],
    dev_host: DevelopmentHostClient,
    dev_tmp_dir: Path,
    token: str,
) -> None:
    """Count, crawl and dump assets with progress bar."""
    # Count total assets to crawl
    total_assets = 0
    for infrastructure in clusters_to_process:
        # Load agent configuration to create cluster
        settings = load_settings(
            "conf/vendor/agent.yml", dev_tmp_dir, f"agent-{infrastructure}.ini"
        )
        auth = SlurmrestdAuthentifier(
            settings.slurmrestd.auth,
            settings.slurmrestd.jwt_mode,
            settings.slurmrestd.jwt_user,
            settings.slurmrestd.jwt_key,
            settings.slurmrestd.jwt_lifespan,
            settings.slurmrestd.jwt_token,
        )
        cluster = DevelopmentHostCluster(
            dev_host, infrastructure, settings.slurmrestd.uri, auth
        )

        # Count assets for each component
        if "slurmrestd" in components_to_process:
            slurmrestd_crawler = SlurmrestdCrawler(cluster, auth)
            total_assets += slurmrestd_crawler.count_assets_to_crawl()

        if "gateway" in components_to_process:
            if infrastructure == GATEWAY_PREFERRED_INFRASTRUCTURE:
                gateway_crawler = GatewayCrawler(
                    token,
                    cluster,
                    infrastructure,
                    dev_tmp_dir,
                )
                total_assets += gateway_crawler.count_assets_to_crawl()

        # Count agent and prometheus (they don't use ComponentCrawler)
        if "agent" in components_to_process:
            agent_path = ASSETS_ROOT / "agent"
            if not (agent_path.exists() and any(agent_path.glob("*.json"))):
                total_assets += 1

        if "prometheus" in components_to_process:
            if infrastructure == METRICS_PREFERRED_INFRASTRUCTURE:
                prometheus_path = ASSETS_ROOT / "prometheus"
                if not (
                    prometheus_path.exists() and any(prometheus_path.glob("*.json"))
                ):
                    total_assets += 1

    # Create progress bar if stdout is a TTY
    use_progress = sys.stdout.isatty() and total_assets > 0
    progress_bar = SimpleProgressBar(total_assets) if use_progress else None

    try:
        # Now actually crawl the assets
        for infrastructure in clusters_to_process:
            # Load agent configuration
            settings = load_settings(
                "conf/vendor/agent.yml", dev_tmp_dir, f"agent-{infrastructure}.ini"
            )
            auth = SlurmrestdAuthentifier(
                settings.slurmrestd.auth,
                settings.slurmrestd.jwt_mode,
                settings.slurmrestd.jwt_user,
                settings.slurmrestd.jwt_key,
                settings.slurmrestd.jwt_lifespan,
                settings.slurmrestd.jwt_token,
            )
            cluster = DevelopmentHostCluster(
                dev_host, infrastructure, settings.slurmrestd.uri, auth
            )

            # Initialize crawlers and crawl
            if "slurmrestd" in components_to_process:
                slurmrestd = SlurmrestdCrawler(cluster, auth)
                slurmrestd.crawl_all_assets(progress_bar)
            else:
                slurmrestd = None

            gateway = None
            if "gateway" in components_to_process:
                if infrastructure == GATEWAY_PREFERRED_INFRASTRUCTURE:
                    gateway = GatewayCrawler(
                        token,
                        cluster,
                        infrastructure,
                        dev_tmp_dir,
                    )
                    gateway.crawl_all_assets(progress_bar)
                else:
                    logger.info(
                        "Skipping gateway for cluster %s (not preferred "
                        "infrastructure)",
                        infrastructure,
                    )

            # Agent and Prometheus (coarse skip if directory has files)
            crawl_metrics = infrastructure == METRICS_PREFERRED_INFRASTRUCTURE

            if "agent" in components_to_process:
                # Check if agent assets directory exists and has files
                agent_path = ASSETS_ROOT / "agent"
                if agent_path.exists() and any(agent_path.glob("*.json")):
                    logger.info("Skipping agent: assets directory already populated")
                else:
                    logger.info("Crawling agent")
                    cluster.reset_minimal()
                    crawl_agent(settings.service.port, token, metrics=crawl_metrics)
                    if progress_bar:
                        progress_bar.update(1)

            if "prometheus" in components_to_process:
                # Check if prometheus assets directory exists and has files
                if crawl_metrics:
                    prometheus_path = ASSETS_ROOT / "prometheus"
                    exists_prom = prometheus_path.exists() and any(
                        prometheus_path.glob("*.json")
                    )
                    if exists_prom:
                        logger.info(
                            "Skipping prometheus: assets directory already populated"
                        )
                    else:
                        logger.info("Crawling prometheus")
                        crawl_prometheus(
                            settings.metrics.host.geturl(), settings.metrics.job
                        )
                        if progress_bar:
                            progress_bar.update(1)
                else:
                    logger.info(
                        "Skipping prometheus for cluster %s (not metrics "
                        "infrastructure)",
                        infrastructure,
                    )
    finally:
        if progress_bar:
            progress_bar.close()


def main() -> None:
    """Crawl and save test assets from Slurm-web gateway, agent and slurmrestd."""
    parser = argparse.ArgumentParser(
        description="Crawl and save test assets from Slurm-web components"
    )
    parser.add_argument(
        "--clusters",
        nargs="+",
        help="Restrict crawling to specific cluster names (default: all clusters)",
    )
    parser.add_argument(
        "--components",
        nargs="+",
        choices=["slurmrestd", "gateway", "agent", "prometheus"],
        help="Restrict crawling to specific components (default: all components)",
    )
    args = parser.parse_args()

    # Setup logger
    setup_logger(
        debug=True,
        log_flags=["ALL"],
        debug_flags=DEBUG_FLAGS,
    )

    # Search for slurm-web development environment temporary directory
    dev_tmp_dirs = list(Path("/tmp").glob("slurm-web-*"))
    try:
        assert len(dev_tmp_dirs) == 1
    except AssertionError:
        logger.error(
            "Unexpectedly found %d Slurm-web development temporary directories",
            len(dev_tmp_dirs),
        )
        sys.exit(1)
    dev_tmp_dir = dev_tmp_dirs[0]
    logger.info(
        "Slurm-web development environment temporary directory: %s", dev_tmp_dir
    )

    # Load cluster list from RacksDB database
    db = RacksDB.load(db="dev/firehpc/db", schema="../RacksDB/schemas/racksdb.yml")
    all_clusters = list(db.infrastructures.keys())
    logger.info("Available clusters: %s", all_clusters)

    # Filter clusters based on argument
    if args.clusters:
        selected_clusters = [
            cluster for cluster in args.clusters if cluster in all_clusters
        ]
        invalid_clusters = [
            cluster for cluster in args.clusters if cluster not in all_clusters
        ]
        if invalid_clusters:
            logger.error("Invalid cluster names: %s", invalid_clusters)
            logger.error("Available clusters: %s", all_clusters)
            sys.exit(1)
        if not selected_clusters:
            logger.error("No valid clusters selected")
            sys.exit(1)
        clusters_to_process = selected_clusters
        logger.info("Restricting to clusters: %s", clusters_to_process)
    else:
        clusters_to_process = all_clusters
        logger.info("Processing all clusters: %s", clusters_to_process)

    # Determine which components to process
    all_components = ["slurmrestd", "gateway", "agent", "prometheus"]
    if args.components:
        components_to_process = args.components
        logger.info("Restricting to components: %s", components_to_process)
    else:
        components_to_process = all_components
        logger.info("Processing all components: %s", components_to_process)

    dev_host = DevelopmentHostClient(DEV_HOST, USER)
    try:
        dev_host.connect()
    except DevelopmentHostConnectionError as err:
        logger.error(err)
        sys.exit(1)

    # Get Slurm-web JWT for authentication on gateway and agent
    token = slurmweb_token(
        dev_host,
        slurmweb_cluster_name(GATEWAY_PREFERRED_INFRASTRUCTURE),
        GATEWAY_PREFERRED_INFRASTRUCTURE,
        dev_tmp_dir,
    )

    try:
        _run_crawl(
            clusters_to_process,
            components_to_process,
            dev_host,
            dev_tmp_dir,
            token,
        )
    except KeyboardInterrupt:
        logger.warning("Interrupted by user (Ctrl-C)")
        sys.exit(130)


if __name__ == "__main__":
    main()
